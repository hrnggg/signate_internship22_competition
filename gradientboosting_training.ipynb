{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19889,
     "status": "ok",
     "timestamp": 1612455564028,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "m0GkraBvAbRL",
    "outputId": "dcd3d2ee-9ff5-4761-e53d-2758cd79fad5"
   },
   "outputs": [],
   "source": [
    "!pip install -q category_encoders xfeat texthero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29012,
     "status": "ok",
     "timestamp": 1612455573299,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "9-XJJzbTmFbz",
    "outputId": "93a86b2c-6083-42d1-996d-6b06ad6c2e6a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import category_encoders as ce\n",
    "import xfeat\n",
    "import texthero as hero\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28879,
     "status": "ok",
     "timestamp": 1612455573302,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "Zi2Xur1EAxrY"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.backends.cudnn.daterministic = True\n",
    "\n",
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33391,
     "status": "ok",
     "timestamp": 1612455577967,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "G1F4ojk4AyuB"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33237,
     "status": "ok",
     "timestamp": 1612455577970,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "rEhpUTIMA3nn"
   },
   "outputs": [],
   "source": [
    "TRAIN_LEN = len(train)\n",
    "FOLDS = 5\n",
    "NAME = \"baseline001\"\n",
    "\n",
    "BASE_DIR = \"./pretrained_models/selected_num_100_add_remove_urls_2/\"\n",
    "MODEL_DIR = BASE_DIR + \"models/\"\n",
    "DATA_DIR = BASE_DIR + \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39678,
     "status": "ok",
     "timestamp": 1612455584548,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "f1ROokp3lfpX"
   },
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(DATA_DIR + \"train_x.pkl\", 'rb'))\n",
    "test_x = pickle.load(open(DATA_DIR + \"test_x.pkl\", 'rb'))\n",
    "\n",
    "train_y = train[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39549,
     "status": "ok",
     "timestamp": 1612455584549,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "Faj1UYaEv-FB"
   },
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)\n",
    "test_x = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39404,
     "status": "ok",
     "timestamp": 1612455584550,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "YY2XOdG7CKfX"
   },
   "outputs": [],
   "source": [
    "def make_skf(train_x, train_y, random_state=2021):\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=random_state)\n",
    "    folds_idx = [(t, v) for (t, v) in skf.split(train_x, train_y)]\n",
    "    return folds_idx\n",
    "\n",
    "\n",
    "def threshold_optimization(y_true, y_pred, metrics=None):\n",
    "    def f1_opt(x):\n",
    "        if metrics is not None:\n",
    "            score = -metrics(y_true, y_pred >= x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return score\n",
    "    result = minimize(f1_opt, x0=np.array([0.5]), method='Nelder-Mead')\n",
    "    best_threshold = result['x'].item()\n",
    "    return best_threshold\n",
    "\n",
    "\n",
    "def optimized_f1(y_true, y_pred):\n",
    "    bt = threshold_optimization(y_true, y_pred, metrics=f1_score)\n",
    "    score = f1_score(y_true, y_pred >= bt)\n",
    "    return score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39237,
     "status": "ok",
     "timestamp": 1612455584551,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "2X-Ez3i9CR2_"
   },
   "outputs": [],
   "source": [
    "class MyGradientBoostingModel:\n",
    "    def __init__(self, name=None, params=None, fold=None, train_x=None, train_y=None, test_x=None, metrics=None, seeds=None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.name = name\n",
    "        self.params = params\n",
    "        self.metrics = metrics \n",
    "        self.kfold = fold \n",
    "        self.oof = None\n",
    "        self.preds = None\n",
    "        self.seeds = seeds if seeds is not None else [2020] \n",
    "        self.models = {}  \n",
    "\n",
    "    def build_model(self):\n",
    "        model = GradientBoostingClassifier(**self.params)\n",
    "        return model    \n",
    "\n",
    "    def predict_cv(self, pretrained=False, model_dir=MODEL_DIR):\n",
    "        oof_seeds = []\n",
    "        scores_seeds = []\n",
    "        for seed in self.seeds:\n",
    "            oof = []\n",
    "            va_idxes = []\n",
    "            scores = []\n",
    "            train_x = self.train_x.values\n",
    "            train_y = self.train_y.values\n",
    "            fold_idx = self.kfold(self.train_x, self.train_y, random_state=seed) \n",
    "\n",
    "            for cv_num, (tr_idx, va_idx) in enumerate(fold_idx):\n",
    "                tr_x, va_x = train_x[tr_idx], train_x[va_idx]\n",
    "                tr_y, va_y = train_y[tr_idx], train_y[va_idx]\n",
    "                va_idxes.append(va_idx)\n",
    "                model = self.build_model()\n",
    "\n",
    "                model_name = f\"{self.name}_SEED{seed}_FOLD{cv_num}_model.pkl\"\n",
    "                model_path = model_dir + model_name\n",
    "    \n",
    "                if pretrained == False:\n",
    "                  model.fit(tr_x, tr_y)                            \n",
    "                  pickle.dump(model, open(model_name, 'wb'))\n",
    "                else:\n",
    "                  model = pickle.load(open(model_path, 'rb'))\n",
    "                \n",
    "                self.models[model_name] = model \n",
    "                \n",
    "                pred = model.predict_proba(va_x)[:, 1]\n",
    "                oof.append(pred)\n",
    "                \n",
    "                score = self.get_score(va_y, pred)\n",
    "                scores.append(score)\n",
    "                print(f\"SEED:{seed}, FOLD:{cv_num} =====> val_score:{score}\")\n",
    "\n",
    "            va_idxes = np.concatenate(va_idxes)\n",
    "            oof = np.concatenate(oof)\n",
    "            order = np.argsort(va_idxes)\n",
    "            oof = oof[order]\n",
    "            oof_seeds.append(oof)\n",
    "            scores_seeds.append(np.mean(scores))\n",
    "            \n",
    "        oof = np.mean(oof_seeds, axis=0)\n",
    "        self.oof = oof\n",
    "        print(f\"model:{self.name} score:{self.get_score(self.train_y, oof)}\\n\")\n",
    "        return oof      \n",
    "\n",
    "    def inference(self, pretrained=False, model_dir=MODEL_DIR):\n",
    "        preds_seeds = []\n",
    "        for seed in self.seeds:\n",
    "            preds = []\n",
    "            test_x = self.test_x.values\n",
    "            for cv_num in range(FOLDS):\n",
    "                print(f\"-INFERENCE- SEED:{seed}, FOLD:{cv_num}\")\n",
    "                model_name = f\"{self.name}_SEED{seed}_FOLD{cv_num}_model.pkl\"\n",
    "                model_path = model_dir + model_name\n",
    "                if pretrained == False:\n",
    "                  model = self.models[model_name]                \n",
    "                else:\n",
    "                  model = pickle.load(open(model_path, 'rb'))\n",
    "                pred = model.predict_proba(test_x)[:, 1]\n",
    "                preds.append(pred)\n",
    "            preds = np.mean(preds, axis=0)\n",
    "            preds_seeds.append(preds)\n",
    "        preds = np.mean(preds_seeds, axis=0)\n",
    "        self.preds = preds\n",
    "        return preds    \n",
    "    \n",
    "    def get_score(self, y_true, y_pred):\n",
    "        score = self.metrics(y_true, y_pred)\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1595920,
     "status": "ok",
     "timestamp": 1612457141911,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "JkGYB5H4CnkE",
    "outputId": "1080d8b7-55ed-4ab3-ed1c-5ffbcca809c8"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss': 'deviance',\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 1.0,\n",
    "    'criterion': 'mse',\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'max_depth': 3,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_impurity_split': None,\n",
    "    'init': None,\n",
    "    'random_state': 2021,\n",
    "    'max_features': None,\n",
    "    'verbose': False,\n",
    "    'max_leaf_nodes': None,\n",
    "    'warm_start': False,\n",
    "    'validation_fraction': 0.1,\n",
    "    'n_iter_no_change': None,\n",
    "    'tol': 1e-4,\n",
    "    'ccp_alpha': 0.0\n",
    "}\n",
    "\n",
    "model = MyGradientBoostingModel(name=NAME, \n",
    "                    params=params,\n",
    "                    fold=make_skf,\n",
    "                    train_x=train_x,\n",
    "                    train_y=train_y,\n",
    "                    test_x=test_x,\n",
    "                    metrics=optimized_f1, \n",
    "                    seeds=[0, 1, 2]\n",
    "                   )\n",
    "\n",
    "oof = model.predict_cv() \n",
    "preds_bagging = model.inference()\n",
    "\n",
    "best_threshold = threshold_optimization(y_true=train_y, y_pred=oof, metrics=f1_score) \n",
    "print(f\"best_threshold is {best_threshold}\\n\")\n",
    "\n",
    "labels = preds_bagging >= best_threshold"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gradientboosting_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
