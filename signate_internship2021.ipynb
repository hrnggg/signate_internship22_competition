{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhVm6-Izmdii"
   },
   "source": [
    "## import + seed + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28292,
     "status": "ok",
     "timestamp": 1612551174122,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "k6dlHSsIe_bo",
    "outputId": "b9ab24f0-09fd-4838-e3a1-d994a62f35b4"
   },
   "outputs": [],
   "source": [
    "!pip install -q catboost category_encoders xfeat texthero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37559,
     "status": "ok",
     "timestamp": 1612551183850,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "IYF95r6F0ZeW",
    "outputId": "90c7e9a2-cf2f-4ccc-f35a-1f1f41965b88"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import category_encoders as ce\n",
    "import xfeat\n",
    "import texthero as hero\n",
    "from lightgbm import LGBMModel, LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36455,
     "status": "ok",
     "timestamp": 1612551183852,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "2mSJZRI_eB3I"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.backends.cudnn.daterministic = True\n",
    "\n",
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1612551227182,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "t4E5fPydbGAS"
   },
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "NAME = \"baseline001\"\n",
    "\n",
    "BASE_DIR = \"./pretrained_models/selected_num_100_add_remove_urls_2/\"\n",
    "BASE_DIR2 = \"./pretrained_models/selected_num_300_add_remove_urls_and_unique_diff/\"\n",
    "BASE_DIR_CB = \"./pretrained_models/catboost_default_selected_num_100/\"\n",
    "BASE_DIR_XGB = \"./pretrained_models/xgb_default_selected_num_100_2/\"\n",
    "BASE_DIR_MLP = \"./pretrained_models/mlp/\"\n",
    "BASE_DIR_MLP2 = \"./pretrained_models/mlp_2/\"\n",
    "BASE_DIR_BAGGING = \"./pretrained_models/bagging/\"\n",
    "BASE_DIR_GB = \"./pretrained_models/gradientboosting/\"\n",
    "BASE_DIR_ADA = \"./pretrained_models/adaboost/\"\n",
    "BASE_DIR_LR = \"./pretrained_models/logistic_regression/\"\n",
    "BASE_DIR_RF = \"./pretrained_models/random_forest/\"\n",
    "BASE_DIR_ET = \"./pretrained_models/extra_trees/\"\n",
    "\n",
    "MODEL_DIR = BASE_DIR + \"models/\"\n",
    "DATA_DIR = BASE_DIR + \"data/\"\n",
    "MODEL_DIR2 = BASE_DIR2 + \"models/\"\n",
    "DATA_DIR2 = BASE_DIR2 + \"data/\"\n",
    "MODEL_DIR_CB = BASE_DIR_CB + \"models/\"\n",
    "DATA_DIR_CB = BASE_DIR_CB + \"data/\"\n",
    "MODEL_DIR_XGB = BASE_DIR_XGB + \"models/\"\n",
    "DATA_DIR_XGB = BASE_DIR_XGB + \"data/\"\n",
    "MODEL_DIR_MLP = BASE_DIR_MLP2 + \"models/\"\n",
    "DATA_DIR_MLP = BASE_DIR_MLP + \"data/\"\n",
    "MODEL_DIR_BAGGING = BASE_DIR_BAGGING + \"models/\"\n",
    "MODEL_DIR_GB = BASE_DIR_GB + \"models/\"\n",
    "MODEL_DIR_ADA = BASE_DIR_ADA + \"models/\"\n",
    "MODEL_DIR_LR = BASE_DIR_LR + \"models/\"\n",
    "MODEL_DIR_RF = BASE_DIR_RF + \"models/\"\n",
    "MODEL_DIR_ET = BASE_DIR_ET + \"models/\"\n",
    "\n",
    "cols_path = DATA_DIR + \"cols.pkl\"\n",
    "cols_path2 = DATA_DIR2 + \"cols.pkl\"\n",
    "cols_path_xgb = DATA_DIR_XGB + \"cols.pkl\"\n",
    "cols_path_cb = DATA_DIR_CB + \"cols.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lX6o6ztfkjUS"
   },
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1622,
     "status": "ok",
     "timestamp": 1612551279662,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "nBOxcvYsz-5C"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/\"\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "train_y = train[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5750,
     "status": "ok",
     "timestamp": 1612551304811,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "X84ZFrtKkERJ"
   },
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(DATA_DIR + \"train_x.pkl\", 'rb'))\n",
    "test_x = pickle.load(open(DATA_DIR + \"test_x.pkl\", 'rb'))\n",
    "\n",
    "train_x2 = pickle.load(open(DATA_DIR2 + \"train_x.pkl\", 'rb'))\n",
    "test_x2 = pickle.load(open(DATA_DIR2 + \"test_x.pkl\", 'rb'))\n",
    "\n",
    "train_x_mlp = pickle.load(open(DATA_DIR_MLP + \"train_x.pkl\", 'rb'))\n",
    "test_x_mlp = pickle.load(open(DATA_DIR_MLP + \"test_x.pkl\", 'rb'))\n",
    "\n",
    "train_x_rf = train_x.fillna(0)\n",
    "test_x_rf = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0lHFq-yj-kI"
   },
   "source": [
    "## single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1612551308258,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "dmXNbfTs4F_C"
   },
   "outputs": [],
   "source": [
    "def make_skf(train_x, train_y, random_state=2021):\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=random_state)\n",
    "    folds_idx = [(t, v) for (t, v) in skf.split(train_x, train_y)]\n",
    "    return folds_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1612551308840,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "enNQTn5i4KMy"
   },
   "outputs": [],
   "source": [
    "def threshold_optimization(y_true, y_pred, metrics=None):\n",
    "    def f1_opt(x):\n",
    "        if metrics is not None:\n",
    "            score = -metrics(y_true, y_pred >= x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return score\n",
    "    result = minimize(f1_opt, x0=np.array([0.5]), method='Nelder-Mead')\n",
    "    best_threshold = result['x'].item()\n",
    "    return best_threshold\n",
    "\n",
    "def optimized_f1(y_true, y_pred):\n",
    "    bt = threshold_optimization(y_true, y_pred, metrics=f1_score)\n",
    "    score = f1_score(y_true, y_pred >= bt)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1612551318480,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "hHLncOFA4ckr"
   },
   "outputs": [],
   "source": [
    "class MyLGBMModel:\n",
    "    def __init__(self, name=None, params=None, fold=None, train_x=None, train_y=None, test_x=None, metrics=None, seeds=None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.name = name\n",
    "        self.params = params\n",
    "        self.metrics = metrics\n",
    "        self.kfold = fold\n",
    "        self.oof = None\n",
    "        self.preds = None\n",
    "        self.seeds = seeds if seeds is not None else [2020]  \n",
    "        self.models = {}  \n",
    "\n",
    "    def build_model(self):\n",
    "        model = LGBMModel(**self.params)\n",
    "        return model\n",
    "\n",
    "    def predict_cv(self, pretrained=False, model_dir=\"./\"):\n",
    "        oof_seeds = []\n",
    "        scores_seeds = []\n",
    "        for seed in self.seeds:\n",
    "            oof = []\n",
    "            va_idxes = []\n",
    "            scores = []\n",
    "            train_x = self.train_x.values\n",
    "            train_y = self.train_y.values\n",
    "            fold_idx = self.kfold(self.train_x, self.train_y, random_state=seed) \n",
    "\n",
    "            for cv_num, (tr_idx, va_idx) in enumerate(fold_idx):\n",
    "                tr_x, va_x = train_x[tr_idx], train_x[va_idx]\n",
    "                tr_y, va_y = train_y[tr_idx], train_y[va_idx]\n",
    "                va_idxes.append(va_idx)\n",
    "                model = self.build_model()\n",
    "                model_name = f\"{self.name}_SEED{seed}_FOLD{cv_num}_model.pkl\"\n",
    "                model_path = model_dir + model_name\n",
    "    \n",
    "                if pretrained == False:\n",
    "                  model.fit(tr_x, tr_y,\n",
    "                            eval_set=[[va_x, va_y]],\n",
    "                            early_stopping_rounds=100,\n",
    "                            verbose=False)  \n",
    "                  pickle.dump(model, open(model_name, 'wb'))\n",
    "                else:\n",
    "                  model = pickle.load(open(model_path, 'rb'))\n",
    "                \n",
    "                self.models[model_name] = model  \n",
    "                \n",
    "                pred = model.predict(va_x)\n",
    "                oof.append(pred)\n",
    "\n",
    "                score = self.get_score(va_y, pred)\n",
    "                scores.append(score)\n",
    "                print(f\"SEED:{seed}, FOLD:{cv_num} =====> val_score:{score}\")\n",
    "\n",
    "            va_idxes = np.concatenate(va_idxes)\n",
    "            oof = np.concatenate(oof)\n",
    "            order = np.argsort(va_idxes)\n",
    "            oof = oof[order]\n",
    "            oof_seeds.append(oof)\n",
    "            scores_seeds.append(np.mean(scores))\n",
    "            \n",
    "        oof = np.mean(oof_seeds, axis=0)\n",
    "        self.oof = oof\n",
    "        print(f\"model:{self.name} score:{self.get_score(self.train_y, oof)}\\n\")\n",
    "        return oof      \n",
    "\n",
    "    def inference(self, pretrained=False, model_dir=\"./\"):\n",
    "        preds_seeds = []\n",
    "        for seed in self.seeds:\n",
    "            preds = []\n",
    "            test_x = self.test_x.values\n",
    "            for cv_num in range(FOLDS):\n",
    "                print(f\"-INFERENCE- SEED:{seed}, FOLD:{cv_num}\")\n",
    "\n",
    "                model_name = f\"{self.name}_SEED{seed}_FOLD{cv_num}_model.pkl\"\n",
    "                model_path = model_dir + model_name\n",
    "                if pretrained == False:\n",
    "                  model = self.models[model_name]                \n",
    "                else:\n",
    "                  model = pickle.load(open(model_path, 'rb'))\n",
    "\n",
    "                pred = model.predict(test_x)\n",
    "                preds.append(pred)\n",
    "            preds = np.mean(preds, axis=0)\n",
    "            preds_seeds.append(preds)\n",
    "        preds = np.mean(preds_seeds, axis=0)\n",
    "        self.preds = preds\n",
    "        return preds\n",
    "\n",
    "    def tree_importance(self):\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        for i, (tr_idx, va_idx) in enumerate(self.kfold(self.train_x, self.train_y)):\n",
    "            tr_x, va_x = self.train_x.values[tr_idx], self.train_x.values[va_idx]\n",
    "            tr_y, va_y = self.train_y.values[tr_idx], self.train_y.values[va_idx]\n",
    "            model = self.build_model()\n",
    "            model.fit(tr_x, tr_y,\n",
    "                      eval_set=[[va_x, va_y]],\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose=False) \n",
    "            _df = pd.DataFrame()\n",
    "            _df['feature_importance'] = model.feature_importances_\n",
    "            _df['column'] = self.train_x.columns\n",
    "            _df['fold'] = i + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, _df], axis=0, ignore_index=True)\n",
    "        order = feature_importance_df.groupby('column') \\\n",
    "                    .sum()[['feature_importance']] \\\n",
    "                    .sort_values('feature_importance', ascending=False).index[:50]\n",
    "        fig, ax = plt.subplots(figsize=(12, max(4, len(order) * .2)))\n",
    "        sns.boxenplot(data=feature_importance_df, y='column', x='feature_importance', order=order, ax=ax,\n",
    "                      palette='viridis')\n",
    "        fig.tight_layout()\n",
    "        ax.grid()\n",
    "        ax.set_title('feature importance')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        return fig, feature_importance_df\n",
    "    \n",
    "    def get_score(self, y_true, y_pred):\n",
    "        score = self.metrics(y_true, y_pred)\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34462,
     "status": "ok",
     "timestamp": 1612551537387,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "i95fQvxAqe00",
    "outputId": "9f00fa61-31ea-4759-d297-b6266f1fbdb1"
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'binary',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': .5,\n",
    "    \"reg_lambda\": 5,\n",
    "}\n",
    "\n",
    "model = MyLGBMModel(name=NAME, \n",
    "                    params=model_params,\n",
    "                    fold=make_skf,\n",
    "                    train_x=train_x,\n",
    "                    train_y=train_y,\n",
    "                    test_x=test_x,\n",
    "                    metrics=optimized_f1, \n",
    "                    seeds=[0, 1, 2]\n",
    "                   )\n",
    "\n",
    "selected_num = 100 \n",
    "\n",
    "cols = pickle.load(open(cols_path, \"rb\"))\n",
    "selected_cols = cols[:selected_num]\n",
    "\n",
    "model.train_x = model.train_x[selected_cols]\n",
    "model.test_x = model.test_x[selected_cols]\n",
    "\n",
    "oof_lgb = model.predict_cv(pretrained=True, model_dir=MODEL_DIR)  \n",
    "preds_lgb = model.inference() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40463,
     "status": "ok",
     "timestamp": 1612551570782,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "DCakKQXeYU78",
    "outputId": "498461bd-f1ea-408c-85cc-912184a816f6"
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'binary',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': .5,\n",
    "    \"reg_lambda\": 5,\n",
    "}\n",
    "\n",
    "model = MyLGBMModel(name=NAME, \n",
    "                    params=model_params,\n",
    "                    fold=make_skf,\n",
    "                    train_x=train_x2,\n",
    "                    train_y=train_y,\n",
    "                    test_x=test_x2,\n",
    "                    metrics=optimized_f1, \n",
    "                    seeds=[0, 1, 2]\n",
    "                   )\n",
    "\n",
    "\n",
    "selected_num = 300\n",
    "\n",
    "cols = pickle.load(open(cols_path2, \"rb\"))\n",
    "selected_cols = cols[:selected_num]\n",
    "\n",
    "model.train_x = model.train_x[selected_cols]\n",
    "model.test_x = model.test_x[selected_cols]\n",
    "\n",
    "oof_lgb2 = model.predict_cv(pretrained=True, model_dir=MODEL_DIR2)\n",
    "preds_lgb2 = model.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8RGEwnQj2SI"
   },
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1612551681342,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "XA1jCzgHFs1W"
   },
   "outputs": [],
   "source": [
    "def add_mean(df, model_cols):\n",
    "  _df = df.copy()\n",
    "  _df[\"mean\"] = df.mean(axis=1)\n",
    "  for model in model_cols:\n",
    "    group_cols = [col for col in df.columns.values if col.startswith(f\"{model}_\")]\n",
    "    _df[f\"{model}_mean\"] = df[group_cols].mean(axis=1)\n",
    "  for i in range(3):\n",
    "      fold_cols = [col for col in df.columns.values if col.endswith(f\"{i}\")]\n",
    "      _df[f\"fold{i}_mean\"] = df[fold_cols].mean(axis=1)\n",
    "  return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1612551732527,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "vmEtdvruZx5V"
   },
   "outputs": [],
   "source": [
    "class StackingModel:\n",
    "    def __init__(self, \n",
    "                 name=None, \n",
    "                 params_dict=None,\n",
    "                 fold=None, \n",
    "                 train_x=None, \n",
    "                 train_y=None, \n",
    "                 test_x=None, \n",
    "                 train_x_mlp=None, \n",
    "                 test_x_mlp=None,\n",
    "                 metrics=None, \n",
    "                 seeds=None, \n",
    "                 model_path_dict=None, \n",
    "                 cols_dict=None):\n",
    "        self.train_x = train_x        \n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.train_x_mlp = train_x_mlp\n",
    "        self.test_x_mlp = test_x_mlp\n",
    "        self.name = name\n",
    "        self.params_dict = params_dict\n",
    "        self.metrics = metrics \n",
    "        self.kfold = fold \n",
    "        self.oof = None\n",
    "        self.preds = None\n",
    "        self.seeds = seeds if seeds is not None else [2020] \n",
    "        self.model_path_dict = model_path_dict\n",
    "        self.models_inference = {} \n",
    "        self.cols_dict = cols_dict\n",
    "\n",
    "\n",
    "    def build_models(self):\n",
    "        models = {}\n",
    "        models[\"lgb\"] = LGBMModel(**self.params_dict[\"lgb\"])\n",
    "        models[\"xgb\"] = XGBClassifier(**self.params_dict[\"xgb\"])        \n",
    "        models[\"catboost\"] = CatBoostClassifier(**self.params_dict[\"catboost\"])              \n",
    "        models[\"rf\"] = RandomForestClassifier(**self.params_dict[\"rf\"])\n",
    "        models[\"et\"] = ExtraTreesClassifier(**self.params_dict[\"et\"])\n",
    "        models[\"bagging\"] = BaggingClassifier(**self.params_dict[\"bagging\"])\n",
    "        models[\"gb\"] = GradientBoostingClassifier(**self.params_dict[\"gb\"])\n",
    "        models[\"ada\"] = AdaBoostClassifier(**self.params_dict[\"ada\"])\n",
    "        models[\"lr\"] = LogisticRegression(**self.params_dict[\"lr\"])\n",
    "        models[\"mlp\"] = MLPClassifier(**self.params_dict[\"mlp\"])\n",
    "        return models\n",
    "\n",
    "\n",
    "    def predict_cv(self):\n",
    "        df_ = pd.DataFrame()\n",
    "        models = self.build_models()\n",
    "        for key, model in models.items():\n",
    "          print(key)\n",
    "          oof_seeds = []\n",
    "          scores_seeds = []\n",
    "          for seed in self.seeds:\n",
    "              oof = []\n",
    "              va_idxes = []\n",
    "              scores = []\n",
    "              train_x = None              \n",
    "              if key == \"mlp\" or key == \"lr\":\n",
    "                train_x = self.train_x_mlp.values\n",
    "              elif key == \"gb\":\n",
    "                train_x = self.train_x.values\n",
    "              else:\n",
    "                cols = self.cols_dict[key]\n",
    "                selected_num = 100\n",
    "                selected_cols = cols[:selected_num]\n",
    "                train_x = self.train_x[selected_cols].values\n",
    "              train_y = self.train_y.values\n",
    "              fold_idx = self.kfold(self.train_x, self.train_y, random_state=seed) \n",
    "\n",
    "              for cv_num, (tr_idx, va_idx) in enumerate(fold_idx):\n",
    "                  tr_x, va_x = train_x[tr_idx], train_x[va_idx]\n",
    "                  tr_y, va_y = train_y[tr_idx], train_y[va_idx]\n",
    "                  va_idxes.append(va_idx)\n",
    "\n",
    "\n",
    "                  model_name = f\"{self.name}_SEED{seed}_FOLD{cv_num}_model.pkl\"\n",
    "\n",
    "                  if key in self.model_path_dict.keys():\n",
    "                    model_path = self.model_path_dict[key] + model_name\n",
    "                    model = pickle.load(open(model_path, 'rb'))\n",
    "                  else:\n",
    "                    model.fit(tr_x, tr_y)\n",
    "                  self.models_inference[key + model_name] = model\n",
    "                  pred = None\n",
    "                  if key == \"lgb\":\n",
    "                    pred = model.predict(va_x)\n",
    "                  else:\n",
    "                    pred = model.predict_proba(va_x)[:, 1]\n",
    "                  oof.append(pred)\n",
    "\n",
    "                  score = self.get_score(va_y, pred)\n",
    "                  scores.append(score)\n",
    "                  print(f\"SEED:{seed}, FOLD:{cv_num} =====> val_score:{score}\")\n",
    "\n",
    "              va_idxes = np.concatenate(va_idxes)\n",
    "              oof = np.concatenate(oof)\n",
    "              order = np.argsort(va_idxes)\n",
    "              oof = oof[order]\n",
    "              oof_seeds.append(oof)\n",
    "              scores_seeds.append(np.mean(scores))\n",
    "              df_[f'{key}_{seed}'] = oof\n",
    "              \n",
    "          oof = np.mean(oof_seeds, axis=0)\n",
    "          self.oof = oof\n",
    "          print(f\"model:{key} score:{self.get_score(self.train_y, oof)}\\n\")\n",
    "\n",
    "        return df_\n",
    "        \n",
    "\n",
    "    def inference(self):\n",
    "        df_ = pd.DataFrame()\n",
    "        models = self.build_models()\n",
    "        for key, model in models.items():\n",
    "          print(key)\n",
    "          preds_seeds = []\n",
    "          for seed in self.seeds:\n",
    "              preds = []              \n",
    "              test_x = None\n",
    "              if key == \"mlp\" or key == \"lr\":\n",
    "                test_x = self.test_x_mlp.values\n",
    "              elif key == \"gb\":\n",
    "                test_x = self.test_x.values\n",
    "              else:\n",
    "                cols = self.cols_dict[key]\n",
    "                selected_num = 100\n",
    "                selected_cols = cols[:selected_num]\n",
    "                test_x = self.test_x[selected_cols].values\n",
    "              for cv_num in range(FOLDS):\n",
    "                  print(f\"-INFERENCE- SEED:{seed}, FOLD:{cv_num}\")\n",
    "                  model_name = f\"{self.name}_SEED{seed}_FOLD{cv_num}_model.pkl\"\n",
    "                  model = self.models_inference[key + model_name]\n",
    "                  pred = None\n",
    "                  if key == \"lgb\":\n",
    "                    pred = model.predict(test_x)\n",
    "                  else:\n",
    "                    pred = model.predict_proba(test_x)[:, 1]\n",
    "                  preds.append(pred)\n",
    "              preds = np.mean(preds, axis=0)\n",
    "              preds_seeds.append(preds)\n",
    "              df_[f'{key}_{seed}'] = preds\n",
    "          preds = np.mean(preds_seeds, axis=0)\n",
    "        return df_\n",
    "\n",
    "    \n",
    "    def get_score(self, y_true, y_pred):\n",
    "        score = self.metrics(y_true, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138455,
     "status": "ok",
     "timestamp": 1612551872537,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "aNmbeMylt3RV",
    "outputId": "75a9a365-cf22-4f79-ac97-c1662c0c955d"
   },
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'binary',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': .5,\n",
    "    \"reg_lambda\": 5,\n",
    "}\n",
    "params_xgb = {\n",
    "    'n_estimators': 500,\n",
    "    'random_state': 2021,\n",
    "    'objective': 'binary:logistic',\n",
    "    'n_jobs': -1,\n",
    "    'importance_type': 'gain',    \n",
    "}\n",
    "params_cb = {\n",
    "    \"verbose\": False,\n",
    "    \"random_state\": 2021\n",
    "}\n",
    "params_rf = {\n",
    "    'random_state': 2021, \n",
    "}\n",
    "params_et = {\n",
    "    'random_state': 2021, \n",
    "}    \n",
    "params_bagging = {\n",
    "    'base_estimator': None,\n",
    "    'n_estimators': 100,\n",
    "    'max_samples': 1.0,\n",
    "    'max_features': 1.0,\n",
    "    'bootstrap': True,\n",
    "    'bootstrap_features': False,\n",
    "    'oob_score': False,\n",
    "    'warm_start': False,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 2021,\n",
    "    'verbose': 0\n",
    "}\n",
    "params_gb = {\n",
    "    'loss': 'deviance',\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 1.0,\n",
    "    'criterion': 'mse',\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'max_depth': 3,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_impurity_split': None,\n",
    "    'init': None,\n",
    "    'random_state': 2021,\n",
    "    'max_features': None,\n",
    "    'verbose': False,\n",
    "    'max_leaf_nodes': None,\n",
    "    'warm_start': False,\n",
    "    'validation_fraction': 0.1,\n",
    "    'n_iter_no_change': None,\n",
    "    'tol': 1e-4,\n",
    "    'ccp_alpha': 0.0\n",
    "}\n",
    "params_ada = {\n",
    "    'base_estimator': None,\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 1,\n",
    "    'algorithm': 'SAMME.R',\n",
    "    'random_state': 2021\n",
    "}\n",
    "params_lr = {\n",
    "    'penalty': 'l2',\n",
    "    'dual': False,\n",
    "    'tol': 1e-4,\n",
    "    'C': 1.0,\n",
    "    'fit_intercept': True,\n",
    "    'intercept_scaling': 1,\n",
    "    'class_weight': None,\n",
    "    'random_state': 2021,\n",
    "    'solver': 'lbfgs',\n",
    "    'max_iter': 100,\n",
    "    'multi_class': 'auto',\n",
    "    'verbose': 0,\n",
    "    'warm_start': False,\n",
    "    'n_jobs': -1, \n",
    "    'l1_ratio': None\n",
    "}\n",
    "params_mlp = {\n",
    "    'hidden_layer_sizes': (300,),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam', \n",
    "    'alpha': 0.0001,\n",
    "    'batch_size': 'auto',\n",
    "    'learning_rate': 'constant',\n",
    "    'learning_rate_init': 0.001,\n",
    "    'power_t': 0.5,\n",
    "    'max_iter': 500,\n",
    "    'shuffle': True,\n",
    "    'random_state': 2021,\n",
    "    'tol': 1e-4,\n",
    "    'verbose': False,\n",
    "    'warm_start': False,\n",
    "    'momentum': 0.9,\n",
    "    'nesterovs_momentum': True,\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.1,\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'epsilon': 1e-8,\n",
    "    'n_iter_no_change': 10,\n",
    "    'max_fun': 15000\n",
    "}\n",
    "\n",
    "params_dict = {\n",
    "    \"lgb\": params_lgb,\n",
    "    \"xgb\": params_xgb,\n",
    "    \"catboost\": params_cb,\n",
    "    \"rf\": params_rf,\n",
    "    \"et\": params_et,\n",
    "    \"bagging\": params_bagging,\n",
    "    \"gb\": params_gb,\n",
    "    \"ada\": params_ada,\n",
    "    \"lr\": params_lr,\n",
    "    \"mlp\": params_mlp,\n",
    "}\n",
    "\n",
    "model_path_dict = {\n",
    "               \"lgb\": MODEL_DIR,\n",
    "               \"xgb\": MODEL_DIR_XGB,\n",
    "               \"catboost\": MODEL_DIR_CB,           \n",
    "               \"rf\": MODEL_DIR_RF,\n",
    "               \"et\": MODEL_DIR_ET,\n",
    "               \"bagging\": MODEL_DIR_BAGGING,\n",
    "               \"gb\": MODEL_DIR_GB,\n",
    "               \"ada\": MODEL_DIR_ADA,\n",
    "               \"lr\": MODEL_DIR_LR,\n",
    "               \"mlp\": MODEL_DIR_MLP,                                             \n",
    "}\n",
    "\n",
    "cols = pickle.load(open(cols_path, \"rb\"))\n",
    "cols_xgb = pickle.load(open(cols_path_xgb, \"rb\"))\n",
    "cols_cb = pickle.load(open(cols_path_cb, \"rb\"))\n",
    "cols_dict = {\n",
    "    \"lgb\": cols,\n",
    "    \"xgb\": cols_xgb,\n",
    "    \"catboost\": cols_cb,\n",
    "    \"rf\": cols,\n",
    "    \"et\": cols,\n",
    "    \"lr\": cols,\n",
    "    \"bagging\": cols,\n",
    "    \"ada\": cols\n",
    "}\n",
    "\n",
    "model = StackingModel(name=NAME,      \n",
    "                    params_dict=params_dict,\n",
    "                    fold=make_skf,\n",
    "                    train_x=train_x_rf,\n",
    "                    train_y=train_y,\n",
    "                    test_x=test_x_rf,\n",
    "                    train_x_mlp=train_x_mlp,\n",
    "                    test_x_mlp=test_x_mlp,\n",
    "                    metrics=optimized_f1, \n",
    "                    seeds=[0, 1, 2],\n",
    "                    model_path_dict=model_path_dict,\n",
    "                    cols_dict=cols_dict\n",
    "                   )\n",
    "\n",
    "train_preds_df = model.predict_cv() \n",
    "test_preds_df = model.inference()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1612551874096,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "BVKDmCeIuCEp"
   },
   "outputs": [],
   "source": [
    "model_names = list(set([col.split(\"_\")[0] for col in train_preds_df.columns]))\n",
    "train_preds_df = add_mean(train_preds_df, model_names)\n",
    "test_preds_df = add_mean(test_preds_df, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75879,
     "status": "ok",
     "timestamp": 1612551953974,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "v0aB_PnhckZu",
    "outputId": "144d04e4-6ff8-4bbd-8520-8cd469b6ed4e"
   },
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    \"n_estimators\": 10000,\n",
    "    \"objective\": 'binary',\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 31,\n",
    "    \"random_state\": 2021,\n",
    "    \"n_jobs\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    'colsample_bytree': 1.0,\n",
    "    \"reg_lambda\": 0.0,\n",
    "}\n",
    "model = MyLGBMModel(name=NAME, \n",
    "                    params=params_lgb,\n",
    "                    fold=make_skf,\n",
    "                    train_x=train_preds_df,\n",
    "                    train_y=train_y,\n",
    "                    test_x=test_preds_df,\n",
    "                    metrics=optimized_f1, \n",
    "                    seeds=[0, 1, 2]\n",
    "                   )\n",
    "\n",
    "\n",
    "oof_l2 = model.predict_cv()  \n",
    "preds_l2 = model.inference() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKw07UvqjlC8"
   },
   "source": [
    "## blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1612552080225,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "r-gq3CtXkD6y",
    "outputId": "97960c6c-206b-42c5-83f0-f940afe1b648"
   },
   "outputs": [],
   "source": [
    "oof_lst = []\n",
    "oof_lst.append(oof_lgb)\n",
    "oof_lst.append(oof_lgb2)\n",
    "oof_lst.append(oof_l2)\n",
    "preds_lst = []\n",
    "preds_lst.append(preds_lgb)\n",
    "preds_lst.append(preds_lgb2)\n",
    "preds_lst.append(preds_l2)\n",
    "\n",
    "oof_avg = np.mean(oof_lst, axis=0)\n",
    "preds_avg = np.mean(preds_lst, axis=0)\n",
    "\n",
    "best_threshold = threshold_optimization(y_true=train_y, y_pred=oof_avg, metrics=f1_score) \n",
    "print(f\"best_threshold is {best_threshold}\\n\")\n",
    "\n",
    "labels_avg = preds_avg >= best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1612552174216,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "QrmlGrMXna95",
    "outputId": "aa9c4297-454c-4e61-a9ba-90e5d1b14a38"
   },
   "outputs": [],
   "source": [
    "weights = [0.4, 0.4, 0.2]\n",
    "oof_avg2 = weights[0] * oof_lgb + weights[1] * oof_lgb2 + weights[2] * oof_l2\n",
    "preds_avg2 = weights[0] * preds_lgb + weights[1] * preds_lgb2 + weights[2] * preds_l2\n",
    "\n",
    "best_threshold = threshold_optimization(y_true=train_y, y_pred=oof_avg2, metrics=f1_score) \n",
    "print(f\"best_threshold is {best_threshold}\\n\")\n",
    "\n",
    "labels_avg2 = preds_avg2 >= best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1612552272524,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "CQDTb37AqhGs",
    "outputId": "a283b0ce-7ccc-4cfa-911d-2c52a60cb960"
   },
   "outputs": [],
   "source": [
    "oof_lst = []\n",
    "oof_lst.append(oof_avg)\n",
    "oof_lst.append(oof_avg2)\n",
    "preds_lst = []\n",
    "preds_lst.append(preds_avg)\n",
    "preds_lst.append(preds_avg2)\n",
    "\n",
    "oof_avg = np.mean(oof_lst, axis=0)\n",
    "preds_avg = np.mean(preds_lst, axis=0)\n",
    "\n",
    "best_threshold = threshold_optimization(y_true=train_y, y_pred=oof_avg, metrics=f1_score) \n",
    "print(f\"best_threshold is {best_threshold}\\n\")\n",
    "\n",
    "labels_avg = preds_avg >= best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNJxkI_9jsHC"
   },
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1612552279285,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "NikcdzQItj35",
    "outputId": "5e3d9b1f-f84f-4faf-9524-7bb0c7c99e31"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DATA_PATH + 'sample_submit.csv', header=None)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1612552290894,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "ws35FxWutwn5",
    "outputId": "99d48313-c6eb-42dc-b1ae-fb2f812bea00"
   },
   "outputs": [],
   "source": [
    "sub[1] = labels_avg\n",
    "sub = sub.astype(int)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1612552294655,
     "user": {
      "displayName": "Hiro NXX",
      "photoUrl": "",
      "userId": "03722192317931833698"
     },
     "user_tz": -540
    },
    "id": "yYGMk7hntxns"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNkUVnQIOIq7G9AL1tu+CTz",
   "collapsed_sections": [],
   "name": "signate_internship2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
